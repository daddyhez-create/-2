import pandas as pd
import numpy as np
import akshare as ak
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler
import time
from datetime import datetime, timedelta

# è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # Mac
plt.rcParams['axes.unicode_minus'] = False

# ==========================================
# 1. é…ç½®åŒºåŸŸ
# ==========================================
SECTOR_MAPPING = {
    "èˆªç©ºæœºåœº": "èˆªç©ºæœºåœº",
    "é€ çº¸å°åˆ·": "é€ çº¸å°åˆ·",
    "é“¶è¡Œ": "é“¶è¡Œ",
    "æˆ¿åœ°äº§": "æˆ¿åœ°äº§å¼€å‘",
    "é£Ÿå“é¥®æ–™": "é£Ÿå“é¥®æ–™",
    "åŠå¯¼ä½“": "åŠå¯¼ä½“",
    "å®¶ç”¨ç”µå™¨": "å®¶ç”µè¡Œä¸š",
    "çººç»‡æœè£…": "çººç»‡æœè£…",
    "èˆªè¿æ¸¯å£": "èˆªè¿æ¸¯å£"
}

# åŸºç¡€åˆ† (åŸºæœ¬é¢é€»è¾‘é¢„è®¾)
FUNDAMENTAL_PRIORS = {
    "èˆªç©ºæœºåœº": 1.0, "é€ çº¸å°åˆ·": 0.8, "é“¶è¡Œ": 0.5, "æˆ¿åœ°äº§": 0.4, "é£Ÿå“é¥®æ–™": 0.2,
    "åŠå¯¼ä½“": -0.1, "å®¶ç”¨ç”µå™¨": -0.6, "çººç»‡æœè£…": -0.8, "èˆªè¿æ¸¯å£": -0.5
}

# ==========================================
# 2. æ•°æ®è·å–æ¨¡å—
# ==========================================
def get_real_data(lookback_days=365):
    print(">>> [1/3] æ­£åœ¨è·å–æ•°æ®...")
    end_date = datetime.now()
    start_date = end_date - timedelta(days=lookback_days)
    start_str = start_date.strftime("%Y%m%d")
    end_str = end_date.strftime("%Y%m%d")
    
    # --- A. è·å–æ±‡ç‡ (æ–°æµªæ¥å£) ---
    try:
        print("    -> æ­£åœ¨è·å–ç¾å…ƒ/äººæ°‘å¸æ±‡ç‡ (æ–°æµª)...")
        df_fx = ak.currency_boc_sina(symbol="ç¾å…ƒ", start_date=start_str, end_date=end_str)
        df_fx['date'] = pd.to_datetime(df_fx['æ—¥æœŸ'])
        
        # ä¼˜å…ˆç”¨ä¸­è¡ŒæŠ˜ç®—ä»·
        if 'ä¸­è¡ŒæŠ˜ç®—ä»·' in df_fx.columns:
            df_fx['USD_CNY'] = pd.to_numeric(df_fx['ä¸­è¡ŒæŠ˜ç®—ä»·']) / 100
        else:
            df_fx['USD_CNY'] = pd.to_numeric(df_fx['ç°æ±‡å–å‡ºä»·']) / 100
            
        df_fx = df_fx[['date', 'USD_CNY']].sort_values('date').set_index('date')
        df_fx = df_fx.resample('D').ffill() # è¡¥å…¨å‘¨æœ«
        
    except Exception as e:
        print(f"!!! æ±‡ç‡è·å–å¤±è´¥: {e}")
        return None

    # --- B. è·å–è¡Œä¸šæ•°æ® (ä¸œè´¢æ¥å£) ---
    sector_prices = pd.DataFrame()
    print("    -> æ­£åœ¨è·å–è¡Œä¸šæ¿å—æ•°æ® (è¿™å¯èƒ½éœ€è¦å‡ åç§’)...")
    
    for logic_name, em_name in SECTOR_MAPPING.items():
        try:
            df_board = ak.stock_board_industry_hist_em(
                symbol=em_name, start_date=start_str, end_date=end_str, adjust="qfq"
            )
            df_board['date'] = pd.to_datetime(df_board['æ—¥æœŸ'])
            df_board.set_index('date', inplace=True)
            sector_prices[logic_name] = df_board['æ”¶ç›˜']
            time.sleep(0.3)
        except Exception as e:
            print(f"    [è·³è¿‡] {em_name}: {e}")

    # --- C. åˆå¹¶ ---
    if sector_prices.empty: return None
    df_final = pd.merge(sector_prices, df_fx, left_index=True, right_index=True, how='inner')
    return df_final

# ==========================================
# 3. å› å­è®¡ç®—å¼•æ“ (åªç®—å› å­ï¼Œä¸åˆæˆ)
# ==========================================
def calculate_raw_factors(df_data):
    """
    è®¡ç®—æ¯ä¸ªæ¿å—çš„ç»Ÿè®¡Betaå’ŒåŸºç¡€åˆ†ï¼Œè¿”å›åŸå§‹å› å­è¡¨
    """
    if df_data is None: return None
    
    df_ret = df_data.pct_change().dropna()
    fx_ret = df_ret['USD_CNY']
    
    results = []
    
    print(">>> [2/3] æ­£åœ¨è¿›è¡Œæ»åå›å½’åˆ†æ...")
    for sector in SECTOR_MAPPING.keys():
        if sector not in df_ret.columns: continue
            
        sector_ret = df_ret[sector]
        
        # å¯»æ‰¾æœ€ä½³æ»å Beta
        best_beta = 0
        best_r2 = -999
        
        for lag in range(11): # 0-10å¤©æ»å
            y = sector_ret.iloc[lag:].values
            X = fx_ret.shift(lag).iloc[lag:].values.reshape(-1, 1)
            
            if len(y) < 30: continue
            
            model = LinearRegression()
            model.fit(X, y)
            r2 = model.score(X, y)
            
            if r2 > best_r2:
                best_r2 = r2
                best_beta = model.coef_[0]
        
        # ç»Ÿè®¡å› å­ (Stat_Factor):
        # Beta < 0 ä»£è¡¨ æ±‡ç‡è·Œ(å‡å€¼) -> è‚¡ä»·æ¶¨ã€‚
        # ä¸ºäº†è®©å› å­æ–¹å‘ä¸€è‡´ (è¶Šå¤§è¶Šåˆ©å¥½)ï¼Œå– -Beta
        stat_raw = -best_beta
        
        # åŸºç¡€å› å­ (Fund_Factor)
        fund_raw = FUNDAMENTAL_PRIORS.get(sector, 0)
        
        results.append({
            "æ¿å—": sector,
            "Stat_Raw": stat_raw,    # åŸå§‹ç»Ÿè®¡åˆ† (å°šæœªå½’ä¸€åŒ–)
            "Fund_Raw": fund_raw     # åŸå§‹åŸºç¡€åˆ† (-1 ~ 1)
        })
        
    return pd.DataFrame(results)

# ==========================================
# 4. æƒé‡æ•æ„Ÿåº¦åˆ†æ (æ ¸å¿ƒåŠŸèƒ½)
# ==========================================
def analyze_weight_sensitivity(df_factors):
    """
    å¯¹å› å­è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¹¶æµ‹è¯•ä¸åŒæƒé‡ä¸‹çš„æ’å
    """
    print("\n>>> [3/3] æ­£åœ¨è¿›è¡Œæƒé‡æ•æ„Ÿåº¦åˆ†æ...")
    
    df = df_factors.copy()
    
    # 1. å½’ä¸€åŒ– (Normalization)
    # å°†ç»Ÿè®¡åˆ†å’ŒåŸºç¡€åˆ†éƒ½ç¼©æ”¾åˆ° [-1, 1] åŒºé—´ï¼Œä¿è¯æƒé‡è®¡ç®—å…¬å¹³
    scaler = MinMaxScaler(feature_range=(-1, 1))
    df[['Stat_Norm', 'Fund_Norm']] = scaler.fit_transform(df[['Stat_Raw', 'Fund_Raw']])
    
    # 2. å®šä¹‰ä¸‰ç§åœºæ™¯
    scenarios = [
        {"name": "äº¤æ˜“å‹ (é‡ç›˜é¢)", "w1": 0.8, "w2": 0.2},
        {"name": "å‡è¡¡å‹ (æ¨è)",   "w1": 0.6, "w2": 0.4},
        {"name": "æŠ•èµ„å‹ (é‡é€»è¾‘)", "w1": 0.3, "w2": 0.7}
    ]
    
    final_output = df[['æ¿å—']].copy()
    
    print("-" * 60)
    print(f"{'åœºæ™¯':<15} | {'Top 1':<10} | {'Top 2':<10} | {'Top 3':<10}")
    print("-" * 60)
    
    for s in scenarios:
        col_name = f"Score_{s['name'][:3]}" # Score_äº¤æ˜“å‹
        # è®¡ç®—ç»¼åˆåˆ†
        final_output[col_name] = (df['Stat_Norm'] * s['w1']) + (df['Fund_Norm'] * s['w2'])
        
        # æ’åºå¹¶æ‰“å° Top 3
        sorted_df = final_output.sort_values(col_name, ascending=False)
        top_sectors = sorted_df['æ¿å—'].head(3).tolist()
        
        print(f"{s['name']:<15} | {top_sectors[0]:<10} | {top_sectors[1]:<10} | {top_sectors[2]:<10}")

    # 3. è®¡ç®—ç¨³å®šæ€§ (å¹³å‡æ’å)
    # ç®€å•çš„é€»è¾‘ï¼šç®—å‡ºä¸‰ç§æ¨¡å¼ä¸‹çš„å¹³å‡åˆ†ï¼Œå¾—åˆ†è¶Šé«˜çš„è¶Šç¨³
    score_cols = [c for c in final_output.columns if 'Score' in c]
    final_output['Avg_Score'] = final_output[score_cols].mean(axis=1)
    
    # æœ€ç»ˆæ€»æ’å
    final_rank = final_output.sort_values('Avg_Score', ascending=False).reset_index(drop=True)
    
    return final_rank

# ==========================================
# 5. å¯è§†åŒ–
# ==========================================
def plot_final_result(df_rank):
    plt.figure(figsize=(12, 6))
    
    # ç»˜åˆ¶ "Avg_Score" (ç»¼åˆç¨³å®šæ€§å¾—åˆ†)
    df_plot = df_rank.sort_values('Avg_Score', ascending=True) # å‡åºä»¥ä¾¿ç”»æ¨ªå‘æŸ±çŠ¶å›¾
    
    colors = ['#d62728' if x > 0 else '#2ca02c' for x in df_plot['Avg_Score']]
    bars = plt.barh(df_plot['æ¿å—'], df_plot['Avg_Score'], color=colors)
    
    plt.axvline(0, color='black', linewidth=0.8, linestyle='--')
    plt.title('äººæ°‘å¸å‡å€¼åˆ©å¥½ç³»æ•° (åŸºäºå¤šæƒé‡æ•æ„Ÿåº¦åŠ æƒ)', fontsize=14)
    plt.xlabel('ç»¼åˆå¼ºåº¦å¾—åˆ† (å½’ä¸€åŒ–å)')
    
    for bar in bars:
        w = bar.get_width()
        plt.text(w * 1.05 if w>0 else w*1.05-0.1, bar.get_y() + bar.get_height()/2, f'{w:.2f}', va='center', fontsize=9)

    plt.tight_layout()
    plt.show()
import scipy.optimize as sco

# ==========================================
# 6. Black-Litterman æ ¸å¿ƒå¼•æ“ (æ–°å¢æ¨¡å—)
# ==========================================
class BlackLittermanStrategy:
    def __init__(self, price_data, sector_ranks, risk_aversion=2.5, tau=0.05):
        """
        åˆå§‹åŒ– BL æ¨¡å‹
        :param price_data: åŒ…å«å„æ¿å—å†å²æ”¶ç›˜ä»·çš„ DataFrame
        :param sector_ranks: ä¸Šä¸€æ­¥ç®—å‡ºçš„æ¿å—è¯„åˆ†è¡¨ (åŒ…å« 'Avg_Score')
        :param risk_aversion: é£é™©åŒæ¶ç³»æ•° (Delta)ï¼Œé€šå¸¸å– 2.5-3.0
        :param tau: è§‚ç‚¹ä¸ç¡®å®šæ€§ç³»æ•°ï¼Œé€šå¸¸å– 0.025-0.05
        """
        self.risk_aversion = risk_aversion
        self.tau = tau
        self.sector_ranks = sector_ranks.set_index('æ¿å—')
        
        # 1. æ•°æ®æ¸…æ´—ï¼šå‰”é™¤æ±‡ç‡åˆ—ï¼Œåªä¿ç•™æ¿å—ä»·æ ¼
        self.prices = price_data.drop(columns=['USD_CNY', 'date'], errors='ignore')
        if 'date' in self.prices.index.names:
            pass # index is already date
        
        # 2. è®¡ç®—å†å²æ”¶ç›Šç‡ä¸åæ–¹å·®çŸ©é˜µ (Sigma)
        self.returns = self.prices.pct_change().dropna()
        self.assets = self.returns.columns.tolist()
        self.n_assets = len(self.assets)
        
        # å¹´åŒ–åæ–¹å·®çŸ©é˜µ (å‡è®¾252ä¸ªäº¤æ˜“æ—¥)
        self.sigma = self.returns.cov() * 252

    def get_market_equilibrium(self):
        """
        è®¡ç®—å¸‚åœºéšå«å‡è¡¡æ”¶ç›Š (Pi)
        ç”±äºå¾ˆéš¾å®æ—¶è·å–æ¿å—çš„æ€»å¸‚å€¼ï¼Œè¿™é‡Œæˆ‘ä»¬å‡è®¾'ç­‰æƒé‡'ä¸ºå¸‚åœºä¸­æ€§åŸºå‡†(Prior)ï¼Œ
        æˆ–è€…ä½ å¯ä»¥ç†è§£ä¸ºæˆ‘ä»¬å¯¹å¸‚åœºå¸‚å€¼çš„å…ˆéªŒæ˜¯æ— ä¿¡æ¯çš„ã€‚
        """
        # å‡è®¾å¸‚åœºæƒé‡ (ç­‰æƒ) -> ä¹Ÿå¯ä»¥æ¢æˆçœŸå®çš„æµé€šå¸‚å€¼æƒé‡
        w_mkt = np.array([1.0 / self.n_assets] * self.n_assets)
        
        # Pi = Delta * Sigma * w_mkt
        # è¿™æ˜¯å¦‚æœä¸è€ƒè™‘äººæ°‘å¸å‡å€¼ï¼Œå¸‚åœºâ€œç†åº”â€ç»™å‡ºçš„å›æŠ¥
        pi = self.risk_aversion * self.sigma.dot(w_mkt)
        return pi, w_mkt

    def mapping_views(self):
        """
        ã€å…³é”®æ­¥éª¤ã€‘å°† 'Avg_Score' (è§‚ç‚¹åˆ†) æ˜ å°„ä¸º 'Q' (é¢„æœŸæ”¶ç›Šå‘é‡)
        é€»è¾‘ï¼š
        1. ä¹‹å‰çš„ Avg_Score èŒƒå›´å¤§çº¦åœ¨ -1 åˆ° 1 ä¹‹é—´ã€‚
        2. æˆ‘ä»¬ä¸èƒ½ç›´æ¥è¯´ 1åˆ† = 100% æ”¶ç›Šã€‚
        3. æˆ‘ä»¬ç”¨æ¿å—çš„'å¹´åŒ–æ³¢åŠ¨ç‡'ä½œä¸ºé”šç‚¹ã€‚
           å¦‚æœæŸæ¿å—å¾—åˆ† 1.0 (æåº¦çœ‹å¥½)ï¼Œæˆ‘ä»¬é¢„æœŸå®ƒè·‘èµ¢å‡è¡¡æ”¶ç›Š 0.5 ä¸ªæ ‡å‡†å·®ã€‚
        """
        # è®¡ç®—å„æ¿å—å¹´åŒ–æ³¢åŠ¨ç‡
        volatilities = np.sqrt(np.diag(self.sigma))
        
        P = np.eye(self.n_assets) # è§‚ç‚¹çŸ©é˜µ (ç»å¯¹è§‚ç‚¹ï¼Œå¯¹è§’é˜µ)
        Q = np.zeros(self.n_assets) # è§‚ç‚¹æ”¶ç›Šå‘é‡
        
        # ä¿¡å¿ƒçŸ©é˜µ Omega
        # ç®€åŒ–çš„ He-Litterman æ–¹æ³•: Omega = diag(tau * P * Sigma * P.T)
        omega = np.diag(np.diag(self.tau * self.sigma))
        
        print("\n>>> [BLæ¨¡å‹] æ­£åœ¨å°†å®è§‚å› å­æ˜ å°„ä¸ºæ”¶ç›Šè§‚ç‚¹...")
        
        pi, _ = self.get_market_equilibrium()
        
        for i, asset in enumerate(self.assets):
            # è·å–è¯¥æ¿å—çš„å¾—åˆ†
            if asset in self.sector_ranks.index:
                score = self.sector_ranks.loc[asset, 'Avg_Score']
            else:
                score = 0
            
            # --- æ ¸å¿ƒæ˜ å°„é€»è¾‘ ---
            # è§‚ç‚¹æ”¶ç›Š Q = éšå«å‡è¡¡æ”¶ç›Š Pi + ä¸»åŠ¨è§‚ç‚¹
            # ä¸»åŠ¨è§‚ç‚¹ = å¾—åˆ† * æ³¢åŠ¨ç‡ * æ¿€è¿›ç³»æ•° (0.5)
            # å«ä¹‰ï¼šå¦‚æœæ˜¯æ»¡åˆ†ï¼Œæˆ‘é¢„æœŸå®ƒæ¯”å¸‚åœºéšå«æ”¶ç›Šå¤šæ¶¨ 0.5 å€æ³¢åŠ¨ç‡
            active_view = score * volatilities[i] * 0.5
            Q[i] = pi[i] + active_view
            
            # åŠ¨æ€è°ƒæ•´ä¿¡å¿ƒ (Omega)
            # å¦‚æœå¾—åˆ†ç»å¯¹å€¼å¾ˆé«˜(>0.5)ï¼Œè¯´æ˜ä¿¡å·å¼ºçƒˆï¼Œæˆ‘ä»¬ç¼©å°æ–¹å·®(å¢åŠ ä¿¡å¿ƒ)
            if abs(score) > 0.5:
                omega[i, i] *= 0.5 
                
            print(f"    -> {asset:<6} | å¾—åˆ†:{score:>5.2f} | éšå«æ”¶ç›Š:{pi[i]:.2%} -> BLè§‚ç‚¹æ”¶ç›Š:{Q[i]:.2%}")
            
        return P, Q, omega

    def optimize(self):
        """
        è®¡ç®— BL åéªŒæ”¶ç›Šå¹¶ä¼˜åŒ–æƒé‡
        """
        pi, w_mkt = self.get_market_equilibrium()
        P, Q, omega = self.mapping_views()
        
        # --- BL æ ¸å¿ƒå…¬å¼ ---
        # 1. è®¡ç®—ä¸­é—´é¡¹
        tau_sigma_inv = np.linalg.inv(self.tau * self.sigma)
        omega_inv = np.linalg.inv(omega)
        
        # 2. è®¡ç®—åéªŒåæ–¹å·® (Posterior Sigma) çš„é€†
        # M = (tau*Sigma)^-1 + P.T * Omega^-1 * P
        M = tau_sigma_inv + P.T.dot(omega_inv).dot(P)
        M_inv = np.linalg.inv(M)
        
        # 3. è®¡ç®—åéªŒé¢„æœŸæ”¶ç›Š (Posterior E[R])
        # E[R] = M^-1 * [ (tau*Sigma)^-1 * Pi + P.T * Omega^-1 * Q ]
        term1 = tau_sigma_inv.dot(pi)
        term2 = P.T.dot(omega_inv).dot(Q)
        bl_returns = M_inv.dot(term1 + term2)
        
        # 4. è®¡ç®—åéªŒåæ–¹å·® (Posterior Covariance)
        # Sigma_BL = Sigma + M^-1
        bl_sigma = self.sigma + M_inv
        
        # --- å‡å€¼-æ–¹å·®ä¼˜åŒ– (Mean-Variance Optimization) ---
        # ç›®æ ‡ï¼šæœ€å¤§åŒ–å¤æ™®æ¯”ç‡
        print("\n>>> [BLæ¨¡å‹] æ­£åœ¨è¿›è¡Œå‡¸ä¼˜åŒ–æ±‚è§£æœ€ä¼˜æƒé‡...")
        
        def neg_sharpe(weights):
            r = weights.dot(bl_returns)
            vol = np.sqrt(weights.T.dot(bl_sigma).dot(weights))
            return -r / vol # è´Ÿå¤æ™®ï¼Œç”¨äºæ±‚æœ€å°
        
        # çº¦æŸæ¡ä»¶
        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) # æƒé‡å’Œä¸º1
        bounds = tuple((0.0, 0.4) for _ in range(self.n_assets)) # é£æ§ï¼šå•æ¿å—æœ€å¤§ä»“ä½ 40%
        
        init_guess = w_mkt
        opts = sco.minimize(neg_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=constraints)
        
        if not opts.success:
            print("!!! ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç­‰æƒé…ç½®")
            return pd.Series(w_mkt, index=self.assets)
        
        return pd.Series(opts.x, index=self.assets)

# ==========================================
# 7. ä¸»ç¨‹åºç»­å†™ (Integration)
# ==========================================
def run_bl_process(df_data, df_result):
    # å®ä¾‹åŒ–ç­–ç•¥
    bl_strategy = BlackLittermanStrategy(df_data, df_result)
    
    # è·å–ä¼˜åŒ–æƒé‡
    optimal_weights = bl_strategy.optimize()
    
    # æ•´ç†ç»“æœ
    df_allocation = pd.DataFrame({
        'æ¿å—': optimal_weights.index,
        'å»ºè®®æƒé‡': optimal_weights.values
    }).sort_values('å»ºè®®æƒé‡', ascending=False)
    
    # è¿‡æ»¤æ‰æƒé‡æå°çš„å€¼æ˜¾ç¤º
    df_allocation = df_allocation[df_allocation['å»ºè®®æƒé‡'] > 0.001]
    
    print("\n" + "="*40)
    print("ğŸ† Black-Litterman æœ€ç»ˆä»“ä½å»ºè®®")
    print("="*40)
    print(df_allocation)
    
    # ç”»é¥¼å›¾
    plt.figure(figsize=(10, 6))
    plt.pie(df_allocation['å»ºè®®æƒé‡'], labels=df_allocation['æ¿å—'], autopct='%1.1f%%', startangle=140)
    plt.title('åŸºäºäººæ°‘å¸å‡å€¼å› å­çš„ BL æ¨¡å‹èµ„äº§é…ç½®', fontsize=14)
    plt.axis('equal')
    plt.tight_layout()
    plt.show()

# ==========================================
# æ›´æ–° main å‡½æ•°
# ==========================================
if __name__ == "__main__":
    # 1. è·å–çœŸå®æ•°æ®
    df_data = get_real_data(lookback_days=365)
    
    if df_data is not None:
        # 2. è®¡ç®—åŸå§‹å› å­
        df_factors = calculate_raw_factors(df_data)
        
        # 3. è¿è¡Œæƒé‡æ•æ„Ÿåº¦åˆ†æ (å¾—åˆ° Avg_Score)
        df_result = analyze_weight_sensitivity(df_factors)
        
        print("\n>>> æœ€ç»ˆç»¼åˆæ’å (æŒ‰ç¨³å®šæ€§æ’åº):")
        print(df_result[['æ¿å—', 'Avg_Score', 'Score_äº¤æ˜“å‹', 'Score_æŠ•èµ„å‹']])
        
        # 4. ç”»å›¾ (Beta æ’å)
        plot_final_result(df_result)
        
        # ----------------------------------------
        # >>> ç»­å†™éƒ¨åˆ†ï¼šæ‰§è¡Œ BL èµ„äº§é…ç½® <<<
        # ----------------------------------------
        run_bl_process(df_data, df_result)
